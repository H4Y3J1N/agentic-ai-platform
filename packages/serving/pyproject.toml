[tool.poetry]
name = "agentic-ai-serving"
version = "0.1.0"
description = "Local model serving package - vLLM, LoRA, Quantization"
authors = ["Your Name <your@email.com>"]
readme = "README.md"
packages = [{include = "agentic_ai_serving"}]

[tool.poetry.dependencies]
python = "^3.11"
agentic-ai-core = {path = "../core", develop = true}
pydantic = "^2.0"
httpx = "^0.27.0"
openai = "^1.0"  # vLLM uses OpenAI-compatible API

# Optional dependencies for specific features
vllm = {version = "^0.6.0", optional = true}
transformers = {version = "^4.40.0", optional = true}
torch = {version = "^2.0", optional = true}
peft = {version = "^0.10.0", optional = true}  # For LoRA
bitsandbytes = {version = "^0.43.0", optional = true}  # For QLoRA
exllamav2 = {version = "^0.1.0", optional = true}  # For EXL2

[tool.poetry.extras]
vllm = ["vllm", "transformers", "torch"]
lora = ["peft", "transformers", "torch"]
qlora = ["bitsandbytes", "peft", "transformers", "torch"]
exl2 = ["exllamav2", "torch"]
all = ["vllm", "transformers", "torch", "peft", "bitsandbytes", "exllamav2"]

[tool.poetry.group.dev.dependencies]
pytest = "^8.0"
pytest-asyncio = "^0.23.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
